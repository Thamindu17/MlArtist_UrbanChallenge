{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "750be9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train main freq:\n",
      " {0: 666, 1: 614}\n",
      "Train sub  freq:\n",
      " {0: 514, 1: 18, 2: 82, 3: 0, 4: 666}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "SPL = ROOT / \"labels\" / \"splits_hier\"\n",
    "\n",
    "train_df = pd.read_csv(SPL / \"train.csv\")\n",
    "val_df   = pd.read_csv(SPL / \"val.csv\")\n",
    "test_df  = pd.read_csv(SPL / \"test.csv\")\n",
    "\n",
    "NUM_MAIN = train_df[\"main_id\"].max() + 1\n",
    "NUM_SUB  = train_df[\"sub_id\"].max() + 1\n",
    "\n",
    "# Frequencies (train-only to avoid leakage)\n",
    "freq_main = train_df[\"main_id\"].value_counts().reindex(range(NUM_MAIN), fill_value=0)\n",
    "freq_sub  = train_df[\"sub_id\"].value_counts().reindex(range(NUM_SUB),  fill_value=0)\n",
    "\n",
    "print(\"Train main freq:\\n\", freq_main.to_dict())\n",
    "print(\"Train sub  freq:\\n\", freq_sub.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29495897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE weights (main): [0.9593750834465027, 1.040624976158142]\n",
      "CE weights (sub):  [9.727624927791112e-09, 2.777777297069406e-07, 6.097560145690295e-08, 4.999999523162842, 7.507506616377668e-09]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "eps = 1e-6\n",
    "# Simple inverse-frequency weights (stable baseline)\n",
    "w_main_ce = torch.tensor(1.0 / (freq_main.values + eps), dtype=torch.float32)\n",
    "w_sub_ce  = torch.tensor(1.0 / (freq_sub.values  + eps), dtype=torch.float32)\n",
    "\n",
    "# Normalize to mean=1 (optional; CE doesn’t require it, but it stabilizes LR)\n",
    "w_main_ce = w_main_ce * (len(w_main_ce) / w_main_ce.sum())\n",
    "w_sub_ce  = w_sub_ce  * (len(w_sub_ce)  / w_sub_ce.sum())\n",
    "\n",
    "print(\"CE weights (main):\", w_main_ce.tolist())\n",
    "print(\"CE weights (sub): \", w_sub_ce.tolist())\n",
    "\n",
    "# Per-sample weights for the sampler — balance by **sub** label\n",
    "sample_w = train_df[\"sub_id\"].map(lambda j: float(w_sub_ce[int(j)])).to_numpy()\n",
    "sampler  = WeightedRandomSampler(\n",
    "    weights=torch.as_tensor(sample_w, dtype=torch.double),\n",
    "    num_samples=len(sample_w),     # roughly epoch size; can scale up if you want more repeats\n",
    "    replacement=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcbc027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/fj0jgh0s0rg95r58q33kw2b40000gn/T/ipykernel_13929/3035809752.py:22: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(IMAGE_SIZE, IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT, value=(0, 0, 0)),\n"
     ]
    }
   ],
   "source": [
    "import cv2, albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "\n",
    "# Train: random crop+resize to target size (v2 uses 'size'), light flips/colors\n",
    "train_tfms = A.Compose([\n",
    "    A.RandomResizedCrop(size=(IMAGE_SIZE, IMAGE_SIZE), scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ColorJitter(0.2, 0.2, 0.2, 0.1, p=0.3),\n",
    "    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# Val/Test: resize/pad to square, normalize, tensor\n",
    "val_tfms = A.Compose([\n",
    "    A.LongestMaxSize(max_size=IMAGE_SIZE),\n",
    "    A.PadIfNeeded(IMAGE_SIZE, IMAGE_SIZE, border_mode=cv2.BORDER_CONSTANT, value=(0, 0, 0)),\n",
    "    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class HierDataset(Dataset):\n",
    "    def __init__(self, df, tfms):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tfms = tfms\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        p = self.df.loc[i, \"path\"]\n",
    "        im = cv2.imread(p, cv2.IMREAD_UNCHANGED)\n",
    "        if im is None:\n",
    "            raise FileNotFoundError(p)\n",
    "        if im.ndim == 2: im = cv2.cvtColor(im, cv2.COLOR_GRAY2RGB)\n",
    "        else:            im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        x = self.tfms(image=im)[\"image\"]           # already CHW float tensor\n",
    "        y_main = int(self.df.loc[i, \"main_id\"])\n",
    "        y_sub  = int(self.df.loc[i, \"sub_id\"])\n",
    "        return x, torch.tensor(y_main), torch.tensor(y_sub)\n",
    "\n",
    "train_ds = HierDataset(train_df, train_tfms)\n",
    "val_ds   = HierDataset(val_df,   val_tfms)\n",
    "test_ds  = HierDataset(test_df,  val_tfms)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "# NOTE: when using a sampler, don't pass shuffle=True\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=0)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141eef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Params: 1,525,031  | heads: main=2, sub=5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "\n",
    "# ---- Device (reuse if already defined) ----\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available()\n",
    "                      else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(\"Device:\", device)\n",
    "\n",
    "crit_main = nn.CrossEntropyLoss(weight=w_main_ce.to(device))  # main head\n",
    "crit_sub  = nn.CrossEntropyLoss(weight=w_sub_ce.to(device))   # sub head\n",
    "\n",
    "# ---- Losses with class weights (expects w_main_ce / w_sub_ce from Cell 2) ----\n",
    "try:\n",
    "    crit_main, crit_sub\n",
    "except NameError:\n",
    "    # If you restarted the kernel and haven't run Cell 2 yet, fall back to unweighted CE\n",
    "    print(\"Note: falling back to unweighted losses (run Cell 2 for class-weighted CE).\")\n",
    "    crit_main = nn.CrossEntropyLoss()\n",
    "    crit_sub  = nn.CrossEntropyLoss()\n",
    "\n",
    "# ---- Multi-task model: MobileNetV3-Small backbone + 2 classifier heads ----\n",
    "class MultiTaskMobileNetV3(nn.Module):\n",
    "    def __init__(self, num_main: int, num_sub: int):\n",
    "        super().__init__()\n",
    "        weights = MobileNet_V3_Small_Weights.IMAGENET1K_V1  # pretrained ImageNet\n",
    "        self.backbone = mobilenet_v3_small(weights=weights)\n",
    "        in_feats = self.backbone.classifier[-1].in_features\n",
    "        # remove the original single-class head\n",
    "        self.backbone.classifier[-1] = nn.Identity()\n",
    "        # two heads for main + sub\n",
    "        self.head_main = nn.Linear(in_feats, num_main)\n",
    "        self.head_sub  = nn.Linear(in_feats, num_sub)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)              # pooled embedding\n",
    "        logits_main = self.head_main(feats)   # softmax via CrossEntropyLoss\n",
    "        logits_sub  = self.head_sub(feats)\n",
    "        return logits_main, logits_sub\n",
    "\n",
    "NUM_MAIN = int(train_df[\"main_id\"].max()) + 1\n",
    "NUM_SUB  = int(train_df[\"sub_id\"].max()) + 1\n",
    "model = MultiTaskMobileNetV3(NUM_MAIN, NUM_SUB).to(device)\n",
    "\n",
    "# ---- Optimizer & scheduler ----\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n",
    "# small utility: number of trainable params\n",
    "def count_params(m): return sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
    "print(f\"Params: {count_params(model):,}  | heads: main={NUM_MAIN}, sub={NUM_SUB}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b2a7339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss 0.4897 | val_loss 1.2293 | val_acc_main 0.881 | val_acc_sub 0.306 | 20.1s\n",
      "Epoch 02 | train_loss 0.1010 | val_loss 0.7977 | val_acc_main 0.912 | val_acc_sub 0.644 | 17.1s\n",
      "Epoch 03 | train_loss 0.0652 | val_loss 1.1480 | val_acc_main 0.856 | val_acc_sub 0.613 | 17.1s\n",
      "Epoch 04 | train_loss 0.0477 | val_loss 0.7429 | val_acc_main 0.950 | val_acc_sub 0.856 | 17.4s\n",
      "Epoch 05 | train_loss 0.0354 | val_loss 0.9703 | val_acc_main 0.950 | val_acc_sub 0.900 | 17.5s\n",
      "Epoch 06 | train_loss 0.0252 | val_loss 1.1137 | val_acc_main 0.969 | val_acc_sub 0.938 | 16.4s\n",
      "Epoch 07 | train_loss 0.0275 | val_loss 0.9621 | val_acc_main 0.969 | val_acc_sub 0.894 | 16.7s\n",
      "Early stopping.\n",
      "Best checkpoint saved to: models/hier_mnv3_small.pt\n"
     ]
    }
   ],
   "source": [
    "import math, time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "def top1_from_logits(logits, targets):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    n_batches = 0\n",
    "    tot_loss = 0.0\n",
    "    acc_main = 0.0\n",
    "    acc_sub  = 0.0\n",
    "    for xb, y_main, y_sub in loader:\n",
    "        xb      = xb.to(device)\n",
    "        y_main  = y_main.to(device)\n",
    "        y_sub   = y_sub.to(device)\n",
    "\n",
    "        lm, ls  = model(xb)\n",
    "        loss    = crit_main(lm, y_main) + crit_sub(ls, y_sub)\n",
    "\n",
    "        tot_loss += float(loss.detach().cpu().item())\n",
    "        acc_main += top1_from_logits(lm, y_main)\n",
    "        acc_sub  += top1_from_logits(ls, y_sub)\n",
    "        n_batches += 1\n",
    "\n",
    "    return {\n",
    "        \"loss\":    tot_loss / max(1, n_batches),\n",
    "        \"acc_main\": acc_main / max(1, n_batches),\n",
    "        \"acc_sub\":  acc_sub  / max(1, n_batches),\n",
    "    }\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer):\n",
    "    model.train()\n",
    "    tot_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for xb, y_main, y_sub in loader:\n",
    "        xb     = xb.to(device)\n",
    "        y_main = y_main.to(device)\n",
    "        y_sub  = y_sub.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        lm, ls = model(xb)\n",
    "        loss   = crit_main(lm, y_main) + crit_sub(ls, y_sub)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tot_loss += float(loss.detach().cpu().item())\n",
    "        n_batches += 1\n",
    "    return tot_loss / max(1, n_batches)\n",
    "\n",
    "# ==== train ====\n",
    "EPOCHS   = 12\n",
    "PATIENCE = 3\n",
    "best_val = math.inf\n",
    "wait     = 0\n",
    "\n",
    "MODELS_DIR = Path(\"models\"); MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT = MODELS_DIR / \"hier_mnv3_small.pt\"\n",
    "\n",
    "history = []\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "    val_stats = evaluate(model, val_loader)\n",
    "\n",
    "    # step ReduceLROnPlateau on *validation loss*\n",
    "    scheduler.step(val_stats[\"loss\"])\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {ep:02d} | train_loss {tr_loss:.4f} | \"\n",
    "          f\"val_loss {val_stats['loss']:.4f} | \"\n",
    "          f\"val_acc_main {val_stats['acc_main']:.3f} | \"\n",
    "          f\"val_acc_sub {val_stats['acc_sub']:.3f} | {dt:.1f}s\")\n",
    "\n",
    "    history.append({\"epoch\": ep, **val_stats, \"train_loss\": tr_loss})\n",
    "\n",
    "    # early stop on best val loss\n",
    "    if val_stats[\"loss\"] < best_val - 1e-4:\n",
    "        best_val = val_stats[\"loss\"]\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), CKPT)\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"Best checkpoint saved to:\", CKPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edff2994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST -> loss: 0.4302 | acc_main: 0.974 | acc_sub: 0.953\n",
      "\n",
      "=== MAIN report ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "Environmental issues      0.976     0.964     0.970        84\n",
      "         Road issues      0.962     0.974     0.968        77\n",
      "\n",
      "            accuracy                          0.969       161\n",
      "           macro avg      0.969     0.969     0.969       161\n",
      "        weighted avg      0.969     0.969     0.969       161\n",
      "\n",
      "=== SUB report ===\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "             Pothole      0.967     0.908     0.937        65\n",
      "Damaged Road Surface      0.000     0.000     0.000         2\n",
      "     Illegal Parking      0.909     1.000     0.952        10\n",
      " Littering / Garbage      0.988     0.988     0.988        84\n",
      "\n",
      "            accuracy                          0.944       161\n",
      "           macro avg      0.716     0.724     0.719       161\n",
      "        weighted avg      0.962     0.944     0.953       161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1) Load best checkpoint\n",
    "CKPT = Path(\"models/hier_mnv3_small.pt\")\n",
    "model.load_state_dict(torch.load(CKPT, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# 2) Build id→name lists from your train dataframe\n",
    "id2main = (\n",
    "    train_df[[\"main_id\", \"main_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"main_id\")[\"main_name\"]\n",
    "    .tolist()\n",
    ")\n",
    "id2sub = (\n",
    "    train_df[[\"sub_id\", \"sub_name\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"sub_id\")[\"sub_name\"]\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# 3) Quick loss/acc on test (reuses evaluate() from Cell 5)\n",
    "test_stats = evaluate(model, test_loader)\n",
    "print(f\"TEST -> loss: {test_stats['loss']:.4f} | \"\n",
    "      f\"acc_main: {test_stats['acc_main']:.3f} | \"\n",
    "      f\"acc_sub: {test_stats['acc_sub']:.3f}\")\n",
    "\n",
    "# 4) Full classification reports (named)\n",
    "y_true_main, y_pred_main = [], []\n",
    "y_true_sub,  y_pred_sub  = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, y_main, y_sub in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        lm, ls = model(xb)\n",
    "        y_true_main.extend(y_main.numpy())\n",
    "        y_true_sub.extend(y_sub.numpy())\n",
    "        y_pred_main.extend(lm.argmax(1).cpu().numpy())\n",
    "        y_pred_sub.extend(ls.argmax(1).cpu().numpy())\n",
    "\n",
    "y_true_main = np.array(y_true_main); y_pred_main = np.array(y_pred_main)\n",
    "y_true_sub  = np.array(y_true_sub);  y_pred_sub  = np.array(y_pred_sub)\n",
    "\n",
    "print(\"\\n=== MAIN report ===\")\n",
    "print(classification_report(y_true_main, y_pred_main, target_names=id2main, digits=3))\n",
    "\n",
    "print(\"=== SUB report ===\")\n",
    "print(classification_report(y_true_sub, y_pred_sub, target_names=id2sub, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f19bd3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'main_name': 'Environmental issues', 'main_prob': 0.8481562733650208, 'sub_name': 'Littering / Garbage', 'sub_prob': 0.4348079562187195}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lx/fj0jgh0s0rg95r58q33kw2b40000gn/T/ipykernel_13929/328092318.py:35: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(size, size, border_mode=cv2.BORDER_CONSTANT, value=(0, 0, 0)),\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Single-image prediction helper (MAIN + SUB)\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2, torch, numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Build id→name lists aligned to the model head sizes (fills any gaps with placeholders)\n",
    "NUM_MAIN = model.head_main.out_features\n",
    "NUM_SUB  = model.head_sub.out_features\n",
    "\n",
    "id2main = [f\"Unknown-{i}\" for i in range(NUM_MAIN)]\n",
    "for mid, name in (train_df[[\"main_id\",\"main_name\"]].drop_duplicates().itertuples(index=False)):\n",
    "    mid = int(mid)\n",
    "    if 0 <= mid < NUM_MAIN:\n",
    "        id2main[mid] = name\n",
    "\n",
    "id2sub = [f\"Unknown-{i}\" for i in range(NUM_SUB)]\n",
    "for sid, name in (train_df[[\"sub_id\",\"sub_name\"]].drop_duplicates().itertuples(index=False)):\n",
    "    sid = int(sid)\n",
    "    if 0 <= sid < NUM_SUB:\n",
    "        id2sub[sid] = name\n",
    "\n",
    "def preprocess_for_infer(path: str, size=224):\n",
    "    im = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    if im is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    if im.ndim == 2:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    tfm = A.Compose([\n",
    "        A.LongestMaxSize(max_size=size),\n",
    "        A.PadIfNeeded(size, size, border_mode=cv2.BORDER_CONSTANT, value=(0, 0, 0)),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    x = tfm(image=im)[\"image\"].unsqueeze(0)  # 1x3xHxW\n",
    "    return x\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(image_path: str):\n",
    "    model.eval()\n",
    "    xb = preprocess_for_infer(image_path).to(device)\n",
    "    lm, ls = model(xb)  # logits for main and sub heads\n",
    "    pm = F.softmax(lm, dim=1)[0].cpu().numpy()  # probabilities (sum to 1)\n",
    "    ps = F.softmax(ls, dim=1)[0].cpu().numpy()\n",
    "\n",
    "    main_id = int(pm.argmax())\n",
    "    sub_id  = int(ps.argmax())\n",
    "\n",
    "    return {\n",
    "        \"main_name\": id2main[main_id],\n",
    "        \"main_prob\": float(pm[main_id]),\n",
    "        \"sub_name\":  id2sub[sub_id],\n",
    "        \"sub_prob\":  float(ps[sub_id]),\n",
    "    }\n",
    "\n",
    "# Example:\n",
    "print(predict(\"/Users/nithilathawalampitiya/Downloads/pexels-simon-robben-55958-614810.jpg\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf43839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classifyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
